# განცალკევებული კომპლექტი გაერთიანება

ეს სტატია განიხილავს მონაცემთა სტრუქტურას **Disjoint Set Union** ან **DSU**.
ხშირად მას ასევე უწოდებენ **Union Find** მისი ორი ძირითადი ოპერაციის გამო.

მონაცემთა ეს სტრუქტურა უზრუნველყოფს შემდეგ შესაძლებლობებს.
ჩვენ გვეძლევა რამდენიმე ელემენტი, რომელთაგან თითოეული ცალკე ნაკრებია.
DSU-ს ექნება ოპერაცია, რომელიც აერთიანებს ნებისმიერ ორ კომპლექტს და მას შეუძლია თქვას, რომელ კომპლექტშია კონკრეტული ელემენტი.
კლასიკური ვერსია ასევე შემოაქვს მესამე ოპერაციას, მას შეუძლია შექმნას ნაკრები ახალი ელემენტიდან.

ამრიგად, ამ მონაცემთა სტრუქტურის ძირითადი ინტერფეისი შედგება მხოლოდ სამი ოპერაციისგან:

- `make_set(v)` - ქმნის ახალ ნაკრებს, რომელიც შედგება ახალი ელემენტისგან `v`
- `union_sets(a, b)` - აერთიანებს ორ მითითებულ კომპლექტს (სიმრავლე, რომელშიც მდებარეობს ელემენტი `a` და სიმრავლე, რომელშიც არის ელემენტი `b`)
- `find_set(v)` - აბრუნებს კომპლექტის წარმომადგენელს (ასევე უწოდებენ ლიდერს), რომელიც შეიცავს `v` ელემენტს.
ეს წარმომადგენელი არის მისი შესაბამისი ნაკრების ელემენტი.
ის შეირჩევა თითოეულ ნაკრებში თავად მონაცემთა სტრუქტურის მიერ (და შეიძლება შეიცვალოს დროთა განმავლობაში, კერძოდ, `union_sets` ზარების შემდეგ).
ეს წარმომადგენელი შეიძლება გამოყენებულ იქნას იმის შესამოწმებლად, არის თუ არა ორი ელემენტი ერთი და იგივე ნაკრების ნაწილი.
`a` და `b` ზუსტად ერთ ნაკრებშია, თუ `find_set(a) == find_set(b)`.
წინააღმდეგ შემთხვევაში ისინი სხვადასხვა კომპლექტში არიან.

როგორც მოგვიანებით უფრო დეტალურად არის აღწერილი, მონაცემთა სტრუქტურა საშუალებას გაძლევთ განახორციელოთ თითოეული ეს ოპერაცია საშუალოდ თითქმის $O(1)$ დროში.

ასევე ერთ-ერთ ქვეთავში ახსნილია DSU-ის ალტერნატიული სტრუქტურა, რომელიც აღწევს $O(\log n)$-ის უფრო ნელ საშუალო სირთულის, მაგრამ შეიძლება იყოს უფრო ძლიერი ვიდრე ჩვეულებრივი DSU სტრუქტურა.

## შექმენით მონაცემთა ეფექტური სტრუქტურა

ჩვენ ვინახავთ ნაკრებებს **ხეების** სახით: თითოეული ხე შეესაბამება ერთ კომპლექტს.
ხოლო ხის ფესვი იქნება ნაკრების წარმომადგენელი/ლიდერი.

შემდეგ სურათზე ხედავთ ასეთი ხეების წარმოდგენას.

![Example-image of the set representation with trees](DSU_example.png)

დასაწყისში, ყველა ელემენტი იწყება როგორც ერთი ნაკრები, ამიტომ თითოეული წვერო არის საკუთარი ხე.
შემდეგ ჩვენ ვაკავშირებთ კომპლექტს, რომელიც შეიცავს ელემენტს 1 და კომპლექტს, რომელიც შეიცავს ელემენტს 2.
შემდეგ ვაერთებთ კომპლექტს, რომელიც შეიცავს ელემენტს 3 და კომპლექტს, რომელიც შეიცავს ელემენტს 4.
და ბოლო ეტაპზე, ჩვენ ვაკავშირებთ კომპლექტს, რომელიც შეიცავს ელემენტს 1 და კომპლექტს, რომელიც შეიცავს ელემენტს 3.

განხორციელებისთვის ეს ნიშნავს, რომ ჩვენ მოგვიწევს შევინარჩუნოთ მასივი `მშობელი~, რომელიც ინახავს მითითებას მისი უშუალო წინაპრის ხეზე.

### გულუბრყვილო განხორციელება

ჩვენ უკვე შეგვიძლია დავწეროთ Disjoint Set Union მონაცემთა სტრუქტურის პირველი განხორციელება.
თავიდან საკმაოდ არაეფექტური იქნება, მაგრამ მოგვიანებით ჩვენ შეგვიძლია გავაუმჯობესოთ ორი ოპტიმიზაციის გამოყენებით, ისე რომ თითქმის მუდმივი დრო დასჭირდება თითოეული ფუნქციის გამოძახებისთვის.

როგორც ვთქვით, ელემენტების ნაკრების შესახებ ყველა ინფორმაცია ინახება მასივში `მშობელი`.

ახალი ნაკრების შესაქმნელად (ოპერაცია `make_set(v)`), ჩვენ უბრალოდ ვქმნით ხეს ფესვით `v` წვეროში, რაც იმას ნიშნავს, რომ ის არის მისი საკუთარი წინაპარი.

ორი სიმრავლის გაერთიანებისთვის (ოპერაცია `union_sets(a, b)`), ჯერ ვიპოვით სიმრავლის წარმომადგენელს, რომელშიც მდებარეობს `a` და სიმრავლის წარმომადგენელს, რომელშიც მდებარეობს `b`.
თუ წარმომადგენლები იდენტურია, რომ არაფერი გვაქვს გასაკეთებელი, კომპლექტები უკვე გაერთიანებულია.
წინააღმდეგ შემთხვევაში, ჩვენ შეგვიძლია უბრალოდ დავაზუსტოთ, რომ ერთ-ერთი წარმომადგენელი არის მეორე წარმომადგენლის მშობელი - ამით გავაერთიანოთ ორი ხე.

დაბოლოს, პოვნის წარმომადგენლობითი ფუნქციის განხორციელება (ოპერაცია `find_set(v)`):
ჩვენ უბრალოდ ავდივართ `v` წვერის წინაპრებზე, სანამ არ მივაღწევთ ფესვს, ანუ ისეთ წვეროს, რომ წინაპარზე მითითება თავისთავად მივყავართ.
ეს ოპერაცია ადვილად ხორციელდება რეკურსიულად.
```cpp
void make_set(int v) {
    parent[v] = v;
}

int find_set(int v) {
    if (v == parent[v])
        return v;
    return find_set(parent[v]);
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b)
        parent[b] = a;
}
```

თუმცა ეს განხორციელება არაეფექტურია.
მარტივია მაგალითის აგება ისე, რომ ხეები გადაგვარდეს გრძელ ჯაჭვებად.
ამ შემთხვევაში თითოეულ ზარს `find_set(v)` შეიძლება $O(n)$ დრო დასჭირდეს.

ეს შორს არის იმ სირთულისგან, რომელიც ჩვენ გვსურს (თითქმის მუდმივი დრო).
ამიტომ განვიხილავთ ორ ოპტიმიზაციას, რაც საშუალებას მისცემს მნიშვნელოვნად დააჩქაროს მუშაობა.

### ბილიკის შეკუმშვის ოპტიმიზაცია

ეს ოპტიმიზაცია შექმნილია `find_set`-ის დაჩქარებისთვის.

თუ ჩვენ მოვუწოდებთ `find_set(v)` ზოგიერთი წვეროსთვის `v`, რეალურად ვიპოვით წარმომადგენლობას `p` ყველა წვეროსთვის, რომელსაც ვსტუმრობთ გზაზე `v`-სა და ფაქტობრივ წარმომადგენელს `p`-ს შორის.
ხრიკი იმაში მდგომარეობს, რომ ყველა ამ კვანძისთვის ბილიკები უფრო მოკლე იყოს, თითოეული მონახულებული წვერის მშობლის დაყენებით პირდაპირ `p`-ზე.

თქვენ შეგიძლიათ იხილოთ ოპერაცია შემდეგ სურათზე.
მარცხნივ არის ხე, ხოლო მარჯვენა მხარეს არის შეკუმშული ხე `find_set(7)`-ის გამოძახების შემდეგ, რომელიც ამცირებს ბილიკებს მონახულებული კვანძებისთვის 7, 5, 3 და 2.

![Path compression of call `find_set(7)`](DSU_path_compression.png)

`find_set`-ის ახალი განხორციელება შემდეგია:

```cpp
int find_set(int v) {
    if (v == parent[v])
        return v;
    return parent[v] = find_set(parent[v]);
}
```

მარტივი განხორციელება აკეთებს იმას, რაც იყო გამიზნული:
ჯერ იპოვნეთ ნაკრების წარმომადგენელი (root vertex), შემდეგ კი სტეკის განტვირთვის პროცესში მონახულებული კვანძები მიმაგრებულია პირდაპირ წარმომადგენელთან.

ოპერაციის ეს მარტივი მოდიფიკაცია უკვე აღწევს დროის სირთულეს $O(\log n)$ თითო ზარზე საშუალოდ (აქ მტკიცებულების გარეშე).
არის მეორე მოდიფიკაცია, რომელიც კიდევ უფრო აჩქარებს მას.

### გაერთიანება ზომით / წოდებით

ამ ოპტიმიზაციაში ჩვენ შევცვლით `union_set` ოპერაციას.
უფრო ზუსტად, ჩვენ შევცვლით, რომელი ხე მიემაგრება მეორეს.
გულუბრყვილო განხორციელებისას მეორე ხე ყოველთვის პირველს ემაგრებოდა.
პრაქტიკაში ამან შეიძლება გამოიწვიოს ხეები, რომლებიც შეიცავენ $O(n)$ სიგრძის ჯაჭვებს.
ამ ოპტიმიზაციით ჩვენ თავიდან ავიცილებთ ამას ძალიან ფრთხილად არჩევით, თუ რომელი ხე იქნება მიმაგრებული.

არსებობს მრავალი შესაძლო ევრისტიკა, რომლის გამოყენებაც შესაძლებელია.
ყველაზე პოპულარულია შემდეგი ორი მიდგომა:
პირველ მიდგომაში ვიყენებთ ხეების ზომას რანგის სახით, ხოლო მეორეში ვიყენებთ ხის სიღრმეს (უფრო ზუსტად, ხის სიღრმეზე ზედა ზღვარს, რადგან ბილიკის შეკუმშვის გამოყენებისას სიღრმე მცირდება).

ორივე მიდგომაში ოპტიმიზაციის არსი ერთი და იგივეა: ჩვენ ვამაგრებთ ქვედა რანგის ხეს უფრო დიდი რანგის მქონეს.

აქ არის კავშირის განხორციელება ზომის მიხედვით:
```cpp
void make_set(int v) {
    parent[v] = v;
    size[v] = 1;
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (size[a] < size[b])
            swap(a, b);
        parent[b] = a;
        size[a] += size[b];
    }
}
```

და აქ არის კავშირის განხორციელება წოდების მიხედვით, ხეების სიღრმეზე დაყრდნობით:

```cpp
void make_set(int v) {
    parent[v] = v;
    rank[v] = 0;
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (rank[a] < rank[b])
            swap(a, b);
        parent[b] = a;
        if (rank[a] == rank[b])
            rank[a]++;
    }
}
```
ორივე ოპტიმიზაცია ექვივალენტურია დროისა და სივრცის სირთულის თვალსაზრისით. ასე რომ, პრაქტიკაში შეგიძლიათ გამოიყენოთ ნებისმიერი მათგანი.

### დროის სირთულე

როგორც უკვე აღვნიშნეთ, თუ ორივე ოპტიმიზაციას გავაერთიანებთ - ბილიკის შეკუმშვა გაერთიანებასთან ზომის/რანგის მიხედვით - მივაღწევთ თითქმის მუდმივ დროის მოთხოვნას.
გამოდის, რომ საბოლოო ამორტიზებული დროის სირთულე არის $O(\alpha(n))$, სადაც $\alpha(n)$ არის აკერმანის ინვერსიული ფუნქცია, რომელიც ძალიან ნელა იზრდება.
სინამდვილეში ის იმდენად ნელა იზრდება, რომ არ აღემატება $4$-ს ყველა გონივრულ $n$-ზე (დაახლოებით $n < 10^{600}$).

ამორტიზებული სირთულე არის მთლიანი დრო თითო ოპერაციაზე, რომელიც ფასდება მრავალი ოპერაციის თანმიმდევრობით.
იდეა მდგომარეობს იმაში, რომ გარანტირებული იყოს მთელი თანმიმდევრობის მთლიანი დრო, ხოლო ერთჯერადი ოპერაციები იყოს ბევრად უფრო ნელი ვიდრე ამორტიზებული დრო.
Მაგალითად. ჩვენს შემთხვევაში, ერთ ზარს შეიძლება დასჭირდეს $O(\log n)$ უარეს შემთხვევაში, მაგრამ თუ ჩვენ გავაკეთებთ $m$ ასეთ ზარებს უკან, ჩვენ მივიღებთ საშუალო დროს $O(\alpha(n) )$.

ჩვენ ასევე არ წარმოვადგენთ ამ დროის სირთულის მტკიცებულებას, რადგან ის საკმაოდ გრძელი და რთულია.

ასევე, აღსანიშნავია, რომ DSU გაერთიანებით ზომით/რანგის მიხედვით, მაგრამ ბილიკის შეკუმშვის გარეშე მუშაობს $O(\log n)$ დროში თითო შეკითხვაზე.

### დაკავშირება ინდექსის / მონეტის გადაბრუნების ბმულით

როგორც კავშირი რანგის მიხედვით, ასევე გაერთიანება ზომით მოითხოვს, რომ შეინახოთ დამატებითი მონაცემები თითოეული ნაკრებისთვის და შეინარჩუნოთ ეს მნიშვნელობები ყოველი კავშირის ოპერაციის დროს.
ასევე არსებობს რანდომიზებული ალგორითმი, რომელიც ცოტათი ამარტივებს კავშირის ოპერაციას: დაკავშირება ინდექსით.

თითოეულ კომპლექტს ვანიჭებთ შემთხვევით მნიშვნელობას, რომელსაც ეწოდება ინდექსი, და ჩვენ ვამაგრებთ კომპლექტს პატარა ინდექსით, რომელსაც უფრო დიდი აქვს.
სავარაუდოა, რომ უფრო დიდ კომპლექტს ექნება უფრო დიდი ინდექსი, ვიდრე პატარა კომპლექტს, ამიტომ ეს ოპერაცია მჭიდროდ არის დაკავშირებული გაერთიანებასთან ზომით.
ფაქტიურად შეიძლება დადასტურდეს, რომ ამ ოპერაციას აქვს იგივე დროის სირთულე, რაც გაერთიანებას ზომით.
თუმცა პრაქტიკაში ის ოდნავ ნელია ვიდრე გაერთიანება ზომით.

თქვენ შეგიძლიათ იპოვოთ სირთულის მტკიცებულება და კიდევ უფრო მეტი კავშირის ტექნიკა [აქ](http://www.cis.upenn.edu/~sanjeev/papers/soda14_disjoint_set_union.pdf).

```cpp
void make_set(int v) {
    parent[v] = v;
    index[v] = rand();
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (index[a] < index[b])
            swap(a, b);
        parent[b] = a;
    }
}
```

გავრცელებული მცდარი წარმოდგენაა, რომ მონეტის გადატრიალებას, იმის გადაწყვეტა, თუ რომელი ნაკრები მივამაგროთ მეორეს, იგივე სირთულეა.
თუმცა ეს არ არის სიმართლე.
ზემოთ მიბმული ნაშრომი ვარაუდობს, რომ მონეტა-გადატრიალებას გზის შეკუმშვასთან ერთად აქვს $\Omega\left(n \frac{\log n}{\log \log n}\right)$ სირთულე.
და კრიტერიუმებში ის ბევრად უარესად მუშაობს, ვიდრე გაერთიანება ზომით/წოდებით ან ინდექსის მიხედვით.

```cpp
void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (rand() % 2)
            swap(a, b);
        parent[b] = a;
    }
}
```

## აპლიკაციები და სხვადასხვა გაუმჯობესება

ამ განყოფილებაში განვიხილავთ მონაცემთა სტრუქტურის რამდენიმე აპლიკაციას, როგორც ტრივიალურ გამოყენებას, ასევე მონაცემთა სტრუქტურის გარკვეულ გაუმჯობესებას.

### დაკავშირებული კომპონენტები გრაფიკში

ეს არის DSU-ს ერთ-ერთი აშკარა აპლიკაცია.

ფორმალურად პრობლემა განისაზღვრება შემდეგნაირად:
თავდაპირველად გვაქვს ცარიელი გრაფიკი.
ჩვენ უნდა დავამატოთ წვეროები და მიუმართავი კიდეები და ვუპასუხოთ $(a, b)$-ის ფორმის შეკითხვებს - "არის თუ არა წვეროები $a$ და $b$ გრაფიკის იმავე დაკავშირებულ კომპონენტში?"

აქ ჩვენ შეგვიძლია პირდაპირ გამოვიყენოთ მონაცემთა სტრუქტურა და მივიღოთ გამოსავალი, რომელიც ამუშავებს წვეროს ან კიდეს და შეკითხვას საშუალოდ თითქმის მუდმივ დროში.

ეს აპლიკაცია საკმაოდ მნიშვნელოვანია, რადგან თითქმის იგივე პრობლემა ჩნდება [Kruskal's algorithm for find a minimum spanning tree](../graph/mst_kruskal.md).
DSU-ს გამოყენებით ჩვენ შეგვიძლია [გავაუმჯობესოთ](../graph/mst_kruskal_with_dsu.md) $O(m \log n + n^2)$ სირთულის $O(m \log n)$-მდე.

### მოძებნეთ დაკავშირებული კომპონენტები სურათში

DSU-ს ერთ-ერთი აპლიკაცია შემდეგი ამოცანაა:
არის $n \ჯერ m$ პიქსელის სურათი.
თავდაპირველად ყველა თეთრია, მაგრამ შემდეგ დახატულია რამდენიმე შავი პიქსელი.
გსურთ განსაზღვროთ თითოეული თეთრი დაკავშირებული კომპონენტის ზომა საბოლოო სურათში.

ამოხსნისთვის ჩვენ უბრალოდ ვიმეორებთ სურათზე ყველა თეთრ პიქსელზე, თითოეული უჯრედისთვის ვიმეორებთ მის ოთხ მეზობელს და თუ მეზობელი თეთრია მოვუწოდებთ `union_sets`.
ამრიგად, ჩვენ გვექნება DSU $n m$ კვანძებით, რომლებიც შეესაბამება გამოსახულების პიქსელებს.
DSU-ში მიღებული ხეები არის სასურველი დაკავშირებული კომპონენტები.

პრობლემის მოგვარება ასევე შესაძლებელია [DFS](../graph/depth-first-search.md) ან [BFS](../graph/breadth-first-search.md) საშუალებით, მაგრამ აქ აღწერილი მეთოდი აქვს უპირატესობა:
მას შეუძლია დაამუშავოს მატრიცის მწკრივი მწკრივი (ანუ მწკრივის დასამუშავებლად გვჭირდება მხოლოდ წინა და მიმდინარე მწკრივი და გვჭირდება მხოლოდ ერთი მწკრივის ელემენტებისთვის აგებული DSU) $O(\min(n, m))$-ში მეხსიერება.

### შეინახეთ დამატებითი ინფორმაცია თითოეული ნაკრებისთვის

DSU საშუალებას გაძლევთ მარტივად შეინახოთ დამატებითი ინფორმაცია კომპლექტებში.

მარტივი მაგალითია კომპლექტების ზომა:
ზომების შენახვა უკვე იყო აღწერილი Union by size განყოფილებაში (ინფორმაცია ინახებოდა ნაკრების ამჟამინდელი წარმომადგენლის მიერ).

ანალოგიურად - მისი შენახვით წარმომადგენლობით კვანძებში - ასევე შეგიძლიათ შეინახოთ ნებისმიერი სხვა ინფორმაცია კომპლექტების შესახებ.

### სეგმენტის გასწვრივ გადახტომების შეკუმშვა / ქვემასივების ხაზგარეშე ხატვა

DSU-ს ერთ-ერთი გავრცელებული აპლიკაცია შემდეგია:
არსებობს წვეროების ნაკრები და თითოეულ წვეროს აქვს გამავალი კიდე სხვა წვეროსთან.
DSU-ით შეგიძლიათ იპოვოთ საბოლოო წერტილი, რომელსაც მივიღებთ მას შემდეგ, რაც მივყვებით ყველა კიდეს მოცემული საწყისი წერტილიდან, თითქმის მუდმივ დროში.

ამ აპლიკაციის კარგი მაგალითია **ქვემასივების შეღებვის პრობლემა**.
ჩვენ გვაქვს $L$ სიგრძის სეგმენტი, თითოეულ ელემენტს თავდაპირველად აქვს ფერი 0.
$[l, r]$ ქვემაივი ხელახლა უნდა გავაფერადოთ $c$ ფერით თითოეული მოთხოვნისთვის $(l, r, c)$.
დასასრულს გვინდა ვიპოვოთ თითოეული უჯრედის საბოლოო ფერი.
ჩვენ ვვარაუდობთ, რომ წინასწარ ვიცით ყველა მოთხოვნა, ანუ დავალება ხაზგარეშეა.

გამოსავლისთვის შეგვიძლია გავაკეთოთ DSU, რომელიც თითოეული უჯრედისთვის ინახავს ბმულს მომდევნო შეუღებავ უჯრედთან.
ამრიგად, თავდაპირველად თითოეული უჯრედი თავისკენ მიუთითებს.
სეგმენტის ერთი მოთხოვნილი ხელახლა შეღებვის შემდეგ, ამ სეგმენტის ყველა უჯრედი მიუთითებს სეგმენტის შემდეგ უჯრედზე.

ახლა ამ პრობლემის გადასაჭრელად, ჩვენ განვიხილავთ შეკითხვებს **საპირისპირო თანმიმდევრობით**: ბოლოდან პირველამდე.
ამ გზით, როდესაც ჩვენ ვასრულებთ შეკითხვას, ჩვენ მხოლოდ უნდა დავხატოთ ზუსტად შეუღებავი უჯრედები $[l, r]$ ქვემასივში.
ყველა სხვა უჯრედი უკვე შეიცავს მათ საბოლოო ფერს.
ყველა შეუღებავ უჯრედზე სწრაფად გამეორებისთვის, ჩვენ ვიყენებთ DSU-ს.
ჩვენ ვპოულობთ მარცხნივ ყველაზე შეუღებავ უჯრედს სეგმენტის შიგნით, ხელახლა ვხატავთ მას და მაჩვენებლით გადავდივართ შემდეგ ცარიელ უჯრედზე მარჯვნივ.

აქ ჩვენ შეგვიძლია გამოვიყენოთ DSU ბილიკის შეკუმშვით, მაგრამ არ შეგვიძლია გამოვიყენოთ კავშირი რანგის/ზომის მიხედვით (რადგან მნიშვნელოვანია, ვინ გახდება ლიდერი შერწყმის შემდეგ).
ამიტომ სირთულე იქნება $O(\log n)$ თითო გაერთიანებაზე (რაც ასევე საკმაოდ სწრაფია).

განხორციელება:

```cpp
for (int i = 0; i <= L; i++) {
    make_set(i);
}

for (int i = m-1; i >= 0; i--) {
    int l = query[i].l;
    int r = query[i].r;
    int c = query[i].c;
    for (int v = find_set(l); v <= r; v = find_set(v)) {
        answer[v] = c;
        parent[v] = v + 1;
    }
}
```

არსებობს ერთი ოპტიმიზაცია:
ჩვენ შეგვიძლია გამოვიყენოთ **union რანგის მიხედვით**, თუ მომდევნო შეუღებავ უჯრედს შევინახავთ დამატებით მასივში `end[]`.
შემდეგ ჩვენ შეგვიძლია გავაერთიანოთ ორი კომპლექტი ერთში მათი ევრისტიკის მიხედვით და მივიღებთ ამონახსნებს $O(\alpha(n))$-ში.

### Support distances up to representative

ზოგჯერ DSU-ს კონკრეტულ აპლიკაციებში საჭიროა შეინარჩუნოთ მანძილი წვეროსა და მისი ნაკრების წარმომადგენელს შორის (ანუ ხეში ბილიკის სიგრძე მიმდინარე კვანძიდან ხის ფესვებამდე).

თუ არ გამოვიყენებთ ბილიკების შეკუმშვას, მანძილი არის მხოლოდ რეკურსიული ზარების რაოდენობა.
მაგრამ ეს არაეფექტური იქნება.

თუმცა შესაძლებელია ბილიკის შეკუმშვა, თუ ჩვენ ვინახავთ **დისტანციას მშობლამდე**, როგორც დამატებითი ინფორმაცია თითოეული კვანძისთვის.

განხორციელებისას მოსახერხებელია წყვილთა მასივის გამოყენება `მშობლისთვის[]` და ფუნქცია `find_set` ახლა აბრუნებს ორ რიცხვს: ნაკრების წარმომადგენელს და მანძილს.

```cpp
void make_set(int v) {
    parent[v] = make_pair(v, 0);
    rank[v] = 0;
}

pair<int, int> find_set(int v) {
    if (v != parent[v].first) {
        int len = parent[v].second;
        parent[v] = find_set(parent[v].first);
        parent[v].second += len;
    }
    return parent[v];
}

void union_sets(int a, int b) {
    a = find_set(a).first;
    b = find_set(b).first;
    if (a != b) {
        if (rank[a] < rank[b])
            swap(a, b);
        parent[b] = make_pair(a, 1);
        if (rank[a] == rank[b])
            rank[a]++;
    }
}
```

### მხარი დაუჭირეთ ბილიკის სიგრძის პარიტეტს / ორმხრივობის შემოწმება ონლაინ

ისევე, როგორც ლიდერისთვის ბილიკის სიგრძის გამოთვლა, შესაძლებელია მის წინ მდებარე ბილიკის სიგრძის პარიტეტის შენარჩუნება.
რატომ არის ეს აპლიკაცია ცალკე პუნქტში?

ბილიკის პარიტეტის შენახვის უჩვეულო მოთხოვნა ჩნდება შემდეგ ამოცანაში:
თავდაპირველად გვაძლევენ ცარიელ გრაფიკს, მას შეიძლება დაემატოს კიდეები და უნდა ვუპასუხოთ შეკითხვებს ფორმის "შეკავშირებული კომპონენტი შეიცავს ამ წვეროს **ორმხრივი**?".

ამ პრობლემის გადასაჭრელად, ჩვენ ვქმნით DSU-ს კომპონენტების შესანახად და ვინახავთ ბილიკის პარიტეტს წარმომადგენლამდე თითოეული წვეროსთვის.
ამრიგად, ჩვენ შეგვიძლია სწრაფად შევამოწმოთ, ზღვრის დამატება იწვევს ორმხრივობის დარღვევას თუ არა:
კერძოდ, თუ კიდის ბოლოები დევს ერთსა და იმავე დაკავშირებულ კომპონენტში და აქვთ ლიდერის პარიტეტის სიგრძე, მაშინ ამ კიდის დამატება წარმოქმნის უცნაური სიგრძის ციკლს და კომპონენტი დაკარგავს ორმხრივობის თვისებას.

ერთადერთი სირთულე, რომელსაც ვხვდებით, არის პარიტეტის გამოთვლა `union_find` მეთოდში.

თუ დავამატებთ $(a, b)$ ზღვარს, რომელიც აკავშირებს ორ დაკავშირებულ კომპონენტს ერთში, მაშინ როცა ერთ ხეს მეორეზე მიამაგრებთ, ჩვენ უნდა დავარეგულიროთ პარიტეტი.

მოდით გამოვიტანოთ ფორმულა, რომელიც ითვლის სიმრავლის ლიდერზე გაცემულ პარიტეტს, რომელიც მიმაგრდება სხვა სიმრავლეს.
მოდით $x$ იყოს ბილიკის სიგრძის პარიტეტი $a$ წვეროდან მის ლიდერ $A$-მდე და $y$ როგორც ბილიკის სიგრძის პარიტეტი $b$ წვეროდან მის ლიდერამდე $B$ და $ t$ სასურველი პარიტეტი, რომელიც უნდა მივცეთ $B$-ს შერწყმის შემდეგ.
ბილიკი შეიცავს სამ ნაწილს:
$B$-დან $b$-მდე, $b$-დან $a$-მდე, რომელიც დაკავშირებულია ერთი კიდით და შესაბამისად აქვს პარიტეტი $1$ და $a$-დან $A$-მდე.
ამიტომ ვიღებთ ფორმულას ($\plus$ აღნიშნავს XOR ოპერაციას):

$$t = x \oplus y \oplus 1$$

ამრიგად, მიუხედავად იმისა, თუ რამდენ შეერთებას ვასრულებთ, კიდეების პარიტეტი გადადის ერთი ლიდერიდან მეორეზე.

ჩვენ ვაძლევთ DSU-ს იმპლემენტაციას, რომელიც მხარს უჭერს პარიტეტს. როგორც წინა განყოფილებაში, ჩვენ ვიყენებთ წყვილს წინაპრისა და პარიტეტის შესანახად. გარდა ამისა, თითოეული ნაკრებისთვის ჩვენ ვინახავთ მასივში `bipartite[]` მიუხედავად იმისა, არის ის მაინც ორმხრივი თუ არა.

```cpp
void make_set(int v) {
    parent[v] = make_pair(v, 0);
    rank[v] = 0;
    bipartite[v] = true;
}

pair<int, int> find_set(int v) {
    if (v != parent[v].first) {
        int parity = parent[v].second;
        parent[v] = find_set(parent[v].first);
        parent[v].second ^= parity;
    }
    return parent[v];
}

void add_edge(int a, int b) {
    pair<int, int> pa = find_set(a);
    a = pa.first;
    int x = pa.second;

    pair<int, int> pb = find_set(b);
    b = pb.first;
    int y = pb.second;

    if (a == b) {
        if (x == y)
            bipartite[a] = false;
    } else {
        if (rank[a] < rank[b])
            swap (a, b);
        parent[b] = make_pair(a, x^y^1);
        bipartite[a] &= bipartite[b];
        if (rank[a] == rank[b])
            ++rank[a];
    }
}

bool is_bipartite(int v) {
    return bipartite[find_set(v).first];
}
```

### ხაზგარეშე RMQ (დიაპაზონის მინიმალური მოთხოვნა) $O(\alpha(n))$ საშუალოდ / Arpa's trick { #arpa data-toc-label="Offline RMQ / Arpa's trick"}

ჩვენ გვეძლევა მასივი `a[]` და ჩვენ უნდა გამოვთვალოთ რამდენიმე მინიმუმი მასივის მოცემულ სეგმენტებში.

DSU–სთან ამ პრობლემის გადაჭრის იდეა შემდეგია:
ჩვენ ვიმეორებთ მასივზე და როდესაც ვიქნებით `i`-ე ელემენტზე, ჩვენ ვუპასუხებთ ყველა შეკითხვას `(L, R)` `R == i`-ით.
ამის ეფექტურად გასაკეთებლად ჩვენ შევინარჩუნებთ DSU-ს პირველი `i` ელემენტების გამოყენებით შემდეგი სტრუქტურით: ელემენტის მშობელი არის შემდეგი პატარა ელემენტი მის მარჯვნივ.
შემდეგ ამ სტრუქტურის გამოყენებით, შეკითხვაზე პასუხი იქნება `a[find_set(L)]`, ყველაზე პატარა რიცხვი `L`-დან მარჯვნივ.

ეს მიდგომა აშკარად მუშაობს მხოლოდ ოფლაინში, ანუ თუ წინასწარ ვიცით ყველა შეკითხვა.

ადვილი მისახვედრია, რომ ჩვენ შეგვიძლია გამოვიყენოთ ბილიკის შეკუმშვა.
ჩვენ ასევე შეგვიძლია გამოვიყენოთ კავშირი რანგის მიხედვით, თუ რეალურ ლიდერს ცალკე მასივში ვინახავთ.

```cpp
struct Query {
    int L, R, idx;
};

vector<int> answer;
vector<vector<Query>> container;
```

`container[i]` contains all queries with `R == i`.

```cpp
stack<int> s;
for (int i = 0; i < n; i++) {
    while (!s.empty() && a[s.top()] > a[i]) {
        parent[s.top()] = i;
        s.pop();
    }
    s.push(i);
    for (Query q : container[i]) {
        answer[q.idx] = a[find_set(q.L)];
    }
}
```

დღესდღეობით ეს ალგორითმი ცნობილია როგორც არპას ხრიკი.
მას ეწოდა ამირრეზა ფურახავანის სახელი, რომელმაც დამოუკიდებლად აღმოაჩინა და გაავრცელა ეს ტექნიკა.
მიუხედავად იმისა, რომ ეს ალგორითმი არსებობდა მის აღმოჩენამდე.

### ხაზგარეშე LCA (ყველაზე დაბალი საერთო წინაპარი ხეზე) $O(\alpha(n))$ საშუალოდ {data-toc-label="Offline LCA"}

LCA-ს პოვნის ალგორითმი განხილულია სტატიაში [Lowest Common Ancestor - Tarjan's off-line algorithm](../graph/lca_tarjan.md).
ეს ალგორითმი ადარებს ხელსაყრელ ალგორითმებს LCA-ს საპოვნელად მისი სიმარტივის გამო (განსაკუთრებით ოპტიმალურ ალგორითმთან შედარებით, როგორიც არის [Farach-Colton and Bender](../graph/lca_farachcoltonbender.md)).

### DSU აშკარად შენახვა კომპლექტის სიაში / ამ იდეის აპლიკაციები მონაცემთა სხვადასხვა სტრუქტურების გაერთიანებისას

DSU-ის შენახვის ერთ-ერთი ალტერნატიული გზაა თითოეული ნაკრების შენარჩუნება **მისი ელემენტების აშკარად შენახული სიის სახით**.
ამავდროულად, თითოეული ელემენტი ასევე ინახავს მითითებას მისი ნაკრების წარმომადგენელზე.

ერთი შეხედვით ეს არაეფექტურ მონაცემთა სტრუქტურას ჰგავს:
ორი კომპლექტის კომბინაციით ჩვენ მოგვიწევს ერთი სიის დამატება მეორის ბოლოს და უნდა განვაახლოთ ლიდერობა ერთ-ერთი სიის ყველა ელემენტში.

თუმცა, როგორც ირკვევა, **შეწონილი ევრისტიკის** გამოყენებამ (ზომით კავშირის მსგავსი) შეიძლება მნიშვნელოვნად შეამციროს ასიმპტომური სირთულე:
$O(m + n \log n)$ $m$ მოთხოვნების შესასრულებლად $n$ ელემენტებზე.

შეწონვის ევრისტიკაში ვგულისხმობთ იმას, რომ ჩვენ ყოველთვის **დავუმატებთ ორ კომპლექტიდან პატარას უფრო დიდ ნაკრებს**.
ერთი კომპლექტის მეორეში დამატება მარტივია "union_sets"-ში და დასჭირდება დრო დამატებული ნაკრების ზომის პროპორციულად.
და ლიდერის ძიება `find_set` მიიღებს $O(1)$ შენახვის ამ მეთოდით.

მოდით დავამტკიცოთ **დროის სირთულე** $O(m + n \log n)$ $m$ მოთხოვნების შესრულებისთვის.
ჩვენ დავაფიქსირებთ თვითნებურ ელემენტს $x$ და დავთვლით რამდენად ხშირად შეხებოდა მას შერწყმის ოპერაციაში `union_sets`.
როდესაც ელემენტს $x$ პირველად შეეხებით, ახალი ნაკრების ზომა იქნება მინიმუმ $2$.
როდესაც მას მეორედ შეეხებით, მიღებულ კომპლექტს ექნება ზომა მინიმუმ $4$, რადგან პატარა ნაკრები ემატება უფრო დიდს.
Და ასე შემდეგ.
ეს ნიშნავს, რომ $x$ შეიძლება გადავიდეს მაქსიმუმ $\log n$ შერწყმის ოპერაციებში.
ამრიგად, ყველა წვეროზე ჯამი იძლევა $O(n \log n)$ პლუს $O(1)$ თითოეული მოთხოვნისთვის.

აქ არის განხორციელება:

```cpp
vector<int> lst[MAXN];
int parent[MAXN];

void make_set(int v) {
    lst[v] = vector<int>(1, v);
    parent[v] = v;
}

int find_set(int v) {
    return parent[v];
}

void union_sets(int a, int b) {
    a = find_set(a);
    b = find_set(b);
    if (a != b) {
        if (lst[a].size() < lst[b].size())
            swap(a, b);
        while (!lst[b].empty()) {
            int v = lst[b].back();
            lst[b].pop_back();
            parent[v] = a;
            lst[a].push_back (v);
        }
    }
}
```

მცირე ნაწილის დიდ ნაწილზე დამატების ეს იდეა ასევე შეიძლება გამოყენებულ იქნას უამრავ გადაწყვეტაში, რომლებსაც საერთო არაფერი აქვთ DSU-სთან.

მაგალითად, განიხილეთ შემდეგი **პრობლემა**:
ჩვენ გვეძლევა ხე, თითოეულ ფოთოლს აქვს მინიჭებული ნომერი (იგივე რიცხვი შეიძლება მრავალჯერ გამოჩნდეს სხვადასხვა ფოთლებზე).
ჩვენ გვინდა გამოვთვალოთ სხვადასხვა რიცხვების რაოდენობა ქვეხეში ხის ყველა კვანძისთვის.

ამ ამოცანისთვის იგივე იდეის გამოყენებით შესაძლებელია ამ ამოხსნის მიღება:
ჩვენ შეგვიძლია განვახორციელოთ [DFS](../graph/depth-first-search.md), რომელიც დააბრუნებს მაჩვენებელს მთელი რიცხვების სიმრავლეს - ამ ქვეხეში რიცხვების სიას.
შემდეგ მიმდინარე კვანძზე პასუხის მისაღებად (თუ რა თქმა უნდა ის ფოთოლი არ არის), ჩვენ მოვუწოდებთ DFS-ს ამ კვანძის ყველა ბავშვისთვის და ვაერთებთ ყველა მიღებულ კომპლექტს.
მიღებული ნაკრების ზომა იქნება პასუხი მიმდინარე კვანძისთვის.
იმისათვის, რომ ეფექტურად დააკავშიროთ რამდენიმე ნაკრები, ჩვენ უბრალოდ გამოვიყენებთ ზემოთ აღწერილ რეცეპტს:
ჩვენ ვაერთებთ კომპლექტებს, უბრალოდ, პატარას უფრო დიდს ვუმატებთ.
საბოლოო ჯამში, ჩვენ ვიღებთ $O(n \log^2 n)$ გადაწყვეტას, რადგან ერთი რიცხვი დაემატება სიმრავლეს მაქსიმუმ $O(\log n)$-ჯერ.

### DSU-ის შენახვა მკაფიო ხის სტრუქტურის შენარჩუნებით / ონლაინ ხიდის პოვნა $O(\alpha(n))$-ში საშუალოდ {data-toc-label="DSU-ის შენახვა მკაფიო ხის სტრუქტურის შენარჩუნებით / ონლაინ ხიდის აღმოჩენა"}

DSU-ის ერთ-ერთი ყველაზე ძლიერი პროგრამა არის ის, რომ ის საშუალებას გაძლევთ შეინახოთ როგორც **შეკუმშული, ისე შეუკუმშული ხეები**.
შეკუმშული ფორმა შეიძლება გამოყენებულ იქნას ხეების შერწყმისთვის და გადამოწმებისთვის, არის თუ არა ორი წვერო ერთსა და იმავე ხეში, ხოლო შეუკუმშული ფორმა შეიძლება გამოყენებულ იქნას - მაგალითად - ორ მოცემულ წვეროს შორის ბილიკების მოსაძებნად ან ხის სტრუქტურის სხვა გადაკვეთებისთვის.

განხორციელებისას ეს ნიშნავს, რომ შეკუმშული წინაპრების მასივის გარდა `მშობელი[]` დაგვჭირდება შევინარჩუნოთ არაკომპრესირებული წინაპრების მასივი `რეალური_მშობელი[]`.
ტრივიალურია, რომ ამ დამატებითი მასივის შენარჩუნება არ გააუარესებს სირთულეს:
მასში ცვლილებები ხდება მხოლოდ მაშინ, როდესაც ჩვენ ვაერთებთ ორ ხეს და მხოლოდ ერთ ელემენტში.

მეორეს მხრივ, პრაქტიკაში გამოყენებისას, ჩვენ ხშირად გვჭირდება ხეების დაკავშირება მითითებული კიდის გამოყენებით, გარდა ორი ძირეული კვანძის გამოყენებით.
ეს ნიშნავს, რომ სხვა გზა არ გვაქვს, გარდა იმისა, რომ ერთ-ერთი ხე ხელახლა დავაფესვიანოთ (კიდის ბოლოები ხის ახალ ფესვად გავხადოთ).

ერთი შეხედვით ჩანს, რომ ეს ხელახალი დაფესვიანება ძალიან ძვირია და მნიშვნელოვნად გააუარესებს დროის სირთულეს.
მართლაც, ხის დასაფესვიანებლად $v$ წვეროზე, ჩვენ უნდა გადავიდეთ წვეროდან ძველ ფესვზე და შევცვალოთ მიმართულებები `მშობელი[]` და `ნამდვილი_მშობელი[]` ამ გზაზე ყველა კვანძისთვის.

თუმცა სინამდვილეში ეს არც ისე ცუდია, ჩვენ შეგვიძლია უბრალოდ ხელახლა დავაფესოლოთ წინა სექციების იდეების მსგავსი ორი ხიდან პატარა და საშუალოდ მივიღოთ $O(\log n)$.

დამატებითი დეტალები (დროის სირთულის მტკიცებულების ჩათვლით) შეგიძლიათ იხილოთ სტატიაში [Finding Bridges Online](../graph/bridge-searching-online.md).

## ისტორიული რეტროსპექტივა

DSU მონაცემთა სტრუქტურა დიდი ხანია ცნობილია.

ამ სტრუქტურის ** ხეების ტყის სახით შენახვის ეს გზა, როგორც ჩანს, პირველად აღწერეს გალერმა და ფიშერმა 1964 წელს (Galler, Fisher, "An Improved Equivalence Algorithm), თუმცა ჩატარდა დროის სირთულის სრული ანალიზი. ბევრად მოგვიანებით.

ოპტიმიზაციის ბილიკის შეკუმშვა და კავშირი რანგის მიხედვით შემუშავებულია მაკილროისა და მორისის მიერ და მათგან დამოუკიდებლად ასევე ტრიტერის მიერ.

ჰოპკროფმა და ულმანმა აჩვენეს 1973 წელს დროის სირთულის $O(\log^\star n)$ (Hopcroft, Ullman "Set-merging algorithms") - აქ $\log^\star$ არის **გამეორებული ლოგარითმი** (ეს არის ნელა მზარდი ფუნქცია, მაგრამ მაინც არ არის ისეთი ნელი, როგორც ინვერსიული აკერმანის ფუნქცია).

პირველად $O(\alpha(n))$-ის შეფასება აჩვენეს 1975 წელს (ტარჯანი "კარგი, მაგრამ არა ხაზოვანი ნაკრების კავშირის ალგორითმის ეფექტურობა").
მოგვიანებით, 1985 წელს, მან, ლეუვენთან ერთად, გამოაქვეყნა მრავალი სირთულის ანალიზი რამდენიმე განსხვავებული რანგის ევრისტიკისთვის და გზის შეკუმშვის გზებისთვის (Tarjan, Leeuwen "Worst-case Analysis of Set Union Algorithms").

საბოლოოდ, 1989 წელს ფრედმანმა და საქსმა დაადასტურეს, რომ გამოთვლის მიღებულ მოდელში **ნებისმიერი** ალგორითმი დისოუნიტირებული სიმრავლის გაერთიანების პრობლემისთვის უნდა იმუშაოს მინიმუმ $O(\alpha(n))$ დროში საშუალოდ (Fredman, Saks, "უჯრედის გამოკვლევის სირთულე მონაცემთა დინამიური სტრუქტურების").

## სავაჯიშო

* [TIMUS - Anansi's Cobweb](http://acm.timus.ru/problem.aspx?space=1&num=1671)
* [Codeforces - Roads not only in Berland](http://codeforces.com/contest/25/problem/D)
* [TIMUS - Parity](http://acm.timus.ru/problem.aspx?space=1&num=1003)
* [SPOJ - Strange Food Chain](http://www.spoj.com/problems/CHAIN/)
* [SPOJ - COLORFUL ARRAY](https://www.spoj.com/problems/CLFLARR/)
* [SPOJ - Consecutive Letters](https://www.spoj.com/problems/CONSEC/)
* [Toph - Unbelievable Array](https://toph.co/p/unbelievable-array)
* [HackerEarth - Lexicographically minimal string](https://www.hackerearth.com/practice/data-structures/disjoint-data-strutures/basics-of-disjoint-data-structures/practice-problems/algorithm/lexicographically-minimal-string-6edc1406/description/)
* [HackerEarth - Fight in Ninja World](https://www.hackerearth.com/practice/algorithms/graphs/breadth-first-search/practice-problems/algorithm/containers-of-choclates-1/)

